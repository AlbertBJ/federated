{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AftvNA5VMemJ"
      },
      "source": [
        "# Federated Learning for Image Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Zs2LgZBOMt4M"
      },
      "source": [
        "In this tutorial, we use the classic MNIST training example to introduce the\n",
        "Federated Learning (FL) component of TFF - a set of higher-level interfaces that\n",
        "can be used to perform common types of federated learning tasks, such as\n",
        "federated training, against user-supplied models implemented in TensorFlow.\n",
        "\n",
        "This tutorial, and the Federated Learning API, are intended primarly for users\n",
        "who will want to plug their own TensorFlow models into TFF, treating the latter\n",
        "mostly as a black box. For a more in-depth understanding of TFF and how to\n",
        "implement your own federated learning algorithms, consider also reviewing as a\n",
        "follow-up the tutorial on lower-level interfaces -\n",
        "[Custom Federated Algorithms Part 1](custom_federated_algorithms_1.ipynb) and\n",
        "[Part 2](custom_federated_algorithms_2.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MnUwFbCAKB2r"
      },
      "source": [
        "## Before we start\n",
        "\n",
        "Before we start, please run the following to make sure that your environment is\n",
        "correctly setup. If you don't see a greeting, please refer to the\n",
        "[Installation](../install.md) guide for instructions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 35
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 15810,
          "status": "ok",
          "timestamp": 1550346460426,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "8BKyHkMxKHfV",
        "outputId": "95c9f21c-6cee-4923-e652-58d5229b55c3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Hello, World!'"
            ]
          },
          "execution_count": 1,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "# NOTE: If you are running a Jupyter notebook and installing a locally built\n",
        "# pip package, you may need to uncomment and run the following after editing\n",
        "# the path to point to the '.whl' file on your local filesystem.\n",
        "#\n",
        "# import sys\n",
        "# !{sys.executable} -m pip install tensorflow_federated-*.whl --user\n",
        "\n",
        "import collections\n",
        "from six.moves import range\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.keras.optimizer_v2 import gradient_descent\n",
        "from tensorflow_federated import python as tff\n",
        "\n",
        "nest = tf.contrib.framework.nest\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "tf.enable_eager_execution()\n",
        "tf.enable_resource_variables()\n",
        "tf.compat.v1.enable_v2_behavior()\n",
        "\n",
        "tff.federated_computation(lambda: 'Hello, World!')()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5Cyy2AWbLMKj"
      },
      "source": [
        "## Preparing the input data\n",
        "\n",
        "Let's start with the data. Federated Learning requires a federated data set,\n",
        "i.e., a collection of data from multipe users. Federated data is typically\n",
        "non-[i.i.d.](https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables),\n",
        "which poses a unique set of challenges.\n",
        "\n",
        "In order to facilitate experimentation, we seeded the TFF repository with a few\n",
        "datasets, including a federated version of MNIST that contains a collection of\n",
        "data obtained from real users that reflects their individual handwriting styles.\n",
        "\n",
        "Here's how we can load it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "NayDhCX6SjwE"
      },
      "outputs": [],
      "source": [
        "#@test {\"output\": \"ignore\"}\n",
        "emnist_train, emnist_test = tff.simulation.datasets.emnist.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yeX8BKgPfeFw"
      },
      "source": [
        "The data sets returned by `load_data()` are instances of\n",
        "`tff.simulation.ClientData`, an interface that allows you to enumerate the set\n",
        "of users, to construct a `tf.data.Dataset` that represents the data of a\n",
        "particular user, and to query the structure of individual elements. Here's how\n",
        "you can use this interface to explore the content of the data set. Keep in mind\n",
        "that while this interface allows you to iterate over clients ids, this is only a\n",
        "feature of the simulation data. As you will see shortly, client identities are\n",
        "not used by the federated learning framework - their only purpose is to allow\n",
        "you to select subsets of the data for simulations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 35
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 75,
          "status": "ok",
          "timestamp": 1550346467163,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "kN4-U5nJgKig",
        "outputId": "0f691abd-6bbf-4b6e-c397-0bb42a37fe73"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3383"
            ]
          },
          "execution_count": 3,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(emnist_train.client_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 52
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 76,
          "status": "ok",
          "timestamp": 1550346467293,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "ZyCzIrSegT62",
        "outputId": "4bcf72b6-1219-424e-828c-45cd3efc39c4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(OrderedDict([(u'label', tf.int32), (u'pixels', tf.float32)]),\n",
              " OrderedDict([(u'label', TensorShape([])), (u'pixels', TensorShape([28, 28]))]))"
            ]
          },
          "execution_count": 4,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "emnist_train.output_types, emnist_train.output_shapes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 35
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 159,
          "status": "ok",
          "timestamp": 1550346467509,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "EsvSXGEMgd9G",
        "outputId": "6eb95644-c835-4526-ad63-e1a31873847e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "execution_count": 5,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "example_dataset = emnist_train.create_tf_dataset_for_client(\n",
        "    emnist_train.client_ids[0])\n",
        "\n",
        "example_element = iter(example_dataset).next()\n",
        "\n",
        "example_element['label'].numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 293
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 303,
          "status": "ok",
          "timestamp": 1550346467959,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "OmLV0nfMg98V",
        "outputId": "95b43b82-8d16-4d71-def2-0cbf5fe3a3d4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\u003cmatplotlib.image.AxesImage at 0xdf2a090\u003e"
            ]
          },
          "execution_count": 6,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAECCAYAAAD3k8IpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "\u003cmatplotlib.figure.Figure at 0xdf09950\u003e"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "#@test {\"output\": \"ignore\"}\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "plt.imshow(example_element['pixels'].numpy(), cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lMd01egqy9we"
      },
      "source": [
        "It is customary for data to require some preprocessing before it is fed into the\n",
        "model. Since the data comes in the form of `tf.data.Dataset`s, you will\n",
        "implement such preprocessing as operations on such structures. To illustrate\n",
        "this, here's a simple preprocessing function that flattens the `28x28` images\n",
        "into `784`-element arrays, organizes them into batches, and renames the features\n",
        "from `pixels` and `label` to `x` and `y` for use with Keras. We also throw in a\n",
        "`repeat` over the data set to run several epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "cyG_BMraSuu_"
      },
      "outputs": [],
      "source": [
        "NUM_EPOCHS = 10\n",
        "BATCH_SIZE = 20\n",
        "\n",
        "def preprocess(dataset):\n",
        "  def element_fn(element):\n",
        "    return collections.OrderedDict([\n",
        "      ('x', tf.reshape(element['pixels'], [-1])), ('y', element['label'])])\n",
        "  return dataset.repeat(NUM_EPOCHS).map(element_fn).batch(BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "m9LXykN_jlJw"
      },
      "source": [
        "Let's verify this worked."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 138
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 164,
          "status": "ok",
          "timestamp": 1550346468309,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "VChB7LMQjkYz",
        "outputId": "1f3ca94c-ef25-45e4-d19b-fd9932d1fbf5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "OrderedDict([('x', array([[ 1.,  1.,  1., ...,  1.,  1.,  1.],\n",
              "       [ 1.,  1.,  1., ...,  1.,  1.,  1.],\n",
              "       [ 1.,  1.,  1., ...,  1.,  1.,  1.],\n",
              "       ..., \n",
              "       [ 1.,  1.,  1., ...,  1.,  1.,  1.],\n",
              "       [ 1.,  1.,  1., ...,  1.,  1.,  1.],\n",
              "       [ 1.,  1.,  1., ...,  1.,  1.,  1.]], dtype=float32)), ('y', array([5, 8, 9, 3, 7, 4, 2, 9, 3, 5, 4, 1, 4, 1, 2, 2, 3, 7, 1, 0], dtype=int32))])"
            ]
          },
          "execution_count": 8,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#@test {\"output\": \"ignore\"}\n",
        "preprocessed_example_dataset = preprocess(example_dataset)\n",
        "\n",
        "sample_batch = nest.map_structure(\n",
        "    lambda x: x.numpy(), iter(preprocessed_example_dataset).next())\n",
        "\n",
        "sample_batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JGsMvRQt9Agl"
      },
      "source": [
        "We have almost all the building blocks in place to construct federated data\n",
        "sets.\n",
        "\n",
        "One of the ways to feed federated data to TFF in a simulation is, simply as a\n",
        "Python list, with each element of the list holding the data of an individual\n",
        "user, whether as a list or as an eager `tf.data.Dataset`. Since we already have\n",
        "an interface that provides the latter, let's use it.\n",
        "\n",
        "Here's a simple helper function that will construct a list of datasets from the\n",
        "given set of users as an input to a round of training or evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "_PHMvHAI9xVc"
      },
      "outputs": [],
      "source": [
        "def make_federated_data(client_data, client_ids):\n",
        "  return [preprocess(client_data.create_tf_dataset_for_client(x))\n",
        "          for x in client_ids]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0M9PfjOtAVqw"
      },
      "source": [
        "Now, how do we choose clients?\n",
        "\n",
        "In a typical federated training scenario, we are dealing with potentially a very\n",
        "large population of user devices, only a fraction of which may be available for\n",
        "training at a given point in time. This is the case, for example, when the\n",
        "client devices are mobile phones that participate in training only when plugged\n",
        "into a power source, off a metered network, and otherwise idle.\n",
        "\n",
        "Of course, we are in a simulation environment, and all the data is locally\n",
        "available. Typically then, when running simulations, we would simply sample a\n",
        "random subset of the clients to be involved in each round of training, generally\n",
        "different in each round.\n",
        "\n",
        "That said, as you can find out by studying the paper on\n",
        "[federated model averaging](https://arxiv.org/abs/1602.05629), achieving\n",
        "convergence in a system with randomly sampled subsets of clients in each round\n",
        "can take a while, and it would be impractical to have to run hundreds of rounds\n",
        "in this interactive tutorial.\n",
        "\n",
        "What we'll do instead is, therefore, to sample the set of clients once, and\n",
        "reuse the same set across rounds to speed up convergence. We leave it as an\n",
        "exercise for the reader to modify this colab to simulate random sampling - it is\n",
        "fairly easy to do (once you do, keep in mind that getting the model to converge\n",
        "may take a while)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 52
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 280,
          "status": "ok",
          "timestamp": 1550346468756,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "GZ6NYHxB8xer",
        "outputId": "e4c56ea8-8230-4cb3-9518-27f0ba539d0f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3,\n",
              " \u003cDatasetV1Adapter shapes: OrderedDict([(x, (None, 784)), (y, (None,))]), types: OrderedDict([(x, tf.float32), (y, tf.int32)])\u003e)"
            ]
          },
          "execution_count": 10,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#@test {\"output\": \"ignore\"}\n",
        "NUM_CLIENTS = 3\n",
        "\n",
        "sample_clients = emnist_train.client_ids[0:NUM_CLIENTS]\n",
        "\n",
        "federated_train_data = make_federated_data(emnist_train, sample_clients)\n",
        "\n",
        "len(federated_train_data), federated_train_data[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HOxq4tbi9m8-"
      },
      "source": [
        "## Creating a model with Keras\n",
        "\n",
        "If you are using Keras, you likely already have code that constructs a Keras\n",
        "model. Here's an example of a simple model that will suffice for our needs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "LYCsJGJFWbqt"
      },
      "outputs": [],
      "source": [
        "def create_compiled_keras_model():\n",
        "  model = tf.keras.models.Sequential([\n",
        "      tf.keras.layers.Flatten(input_shape=(784,)),\n",
        "      tf.keras.layers.Dense(\n",
        "          10, activation=tf.nn.softmax, kernel_initializer='zeros')])\n",
        "  def loss_fn(y_true, y_pred):\n",
        "    return tf.reduce_mean(tf.keras.metrics.sparse_categorical_crossentropy(\n",
        "        y_true, y_pred))\n",
        "  model.compile(\n",
        "      loss=loss_fn,\n",
        "      optimizer=gradient_descent.SGD(learning_rate=0.1),\n",
        "      metrics=[])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NHdraKFH4OU2"
      },
      "source": [
        "In order to use any model with TFF, it needs to be wrapped in an instance of the\n",
        "`tff.learning.Model` interface, which exposes methods to stamp the model's\n",
        "forward pass, metadata properties, etc., similarly to Keras, but also introduces\n",
        "additional elements, such as ways to control the process of computing federated\n",
        "metrics. Let's not worry about this for now; if you have a compiled Keras model\n",
        "like the one we've just defined above, you can have TFF wrap it for you by\n",
        "invoking `tff.learning.from_compiled_keras_model`, passing the model and a\n",
        "sample data batch as arguments, as shown below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Q3ynrxd53HzY"
      },
      "outputs": [],
      "source": [
        "def model_fn():\n",
        "  keras_model = create_compiled_keras_model()\n",
        "  return tff.learning.from_compiled_keras_model(keras_model, sample_batch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XJ5E3O18_JZ6"
      },
      "source": [
        "## Training the model on federated data\n",
        "\n",
        "Now that we have a model wrapped as `tff.learning.Model` for use with TFF, we\n",
        "can let TFF construct a federated averaging algorithm by invoking the helper\n",
        "function `tff.learning.build_federated_averaging_process`, as follows.\n",
        "\n",
        "Keep in mind that the argument needs to be a constructor (such as `model_fn`\n",
        "above), not an already-constructed instance, so that the construction of your\n",
        "model can happen in a context controlled by TFF (if you're curious about the\n",
        "reasons for this, we encourage you to read the follow-up tutorial on\n",
        "[custom algorithms](custom_federated_algorithms_1.ipynb))."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "sk6mjOfycX5N"
      },
      "outputs": [],
      "source": [
        "iterative_process = tff.learning.build_federated_averaging_process(model_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "f8FpvN2n67sm"
      },
      "source": [
        "What did just happen? TFF has constructed a pair of *federated computations* and\n",
        "packaged them into a standardized iterator-like structure\n",
        "`tff.utils.IterativeProcess` in which these computations are available as a pair\n",
        "of properties `initialize` and `next`.\n",
        "\n",
        "In a nutshell, *federated computations* are programs in TFF's internal language\n",
        "that can express various federated algorithms (you can find more about this in\n",
        "the [custom algorithms](custom_federated_algorithms_1.ipynb) tutorial). In this\n",
        "case, the two computations generated and packed into `iterative_process`\n",
        "implement [federated model averaging](https://arxiv.org/abs/1602.05629).\n",
        "\n",
        "In one of the upcoming releases of the framework, we'll enable you to deploy\n",
        "such computations for execution in real environments, such as on groups of\n",
        "`Android` devices. In this tutorial, we'll execute federated computations in a\n",
        "simple interpreted environment in a simulator, inside this notebook. To execute\n",
        "a computation in a simulator, you simply invoke it like a Python function, as we\n",
        "will demonstrate shortly. This default interpreted environment is not designed\n",
        "for high performance, but it will suffice for this tutorial.\n",
        "\n",
        "Let's start with the `initialize` computation. As is the case for all federated\n",
        "computations, you can think of it as a function. The computation takes no\n",
        "arguments, and returns one result - the representation of the state of the\n",
        "federated averaging process on the server. While we don't want to dive into the\n",
        "details of TFF, it may be instructive to see what this state looks like. You can\n",
        "visualize it as follows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 35
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 76,
          "status": "ok",
          "timestamp": 1550346471568,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "Z4pcfWsUBp_5",
        "outputId": "754bd9ee-b8fe-41ca-af6e-507860697185"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'( -\u003e \u003cmodel=\u003ctrainable=\u003cdense/kernel=float32[784,10],dense/bias=float32[10]\u003e,non_trainable=\u003c\u003e\u003e,optimizer_state=\u003cint64\u003e\u003e@SERVER)'"
            ]
          },
          "execution_count": 14,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#@test {\"output\": \"ignore\"}\n",
        "str(iterative_process.initialize.type_signature)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "v1gbHQ_7BiyT"
      },
      "source": [
        "While the above type signature may at first seem a bit cryptic, you can\n",
        "recognize that the server state consists of a `model` (the initial model\n",
        "parameters for MNIST that will be distributed to all devices), and\n",
        "`optimizer_state` (additional information maintained by the server, such as the\n",
        "number of rounds to use for hypermarameter schedules, etc.).\n",
        "\n",
        "Let's invoke the `initialize` computation to construct the server state."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "6cagCWlZmcch"
      },
      "outputs": [],
      "source": [
        "state = iterative_process.initialize()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TjjxTx9e_rMd"
      },
      "source": [
        "The second of the pair of federated computations, `next`, represents a single\n",
        "round of federated averaging, which consists of pushing the server state\n",
        "(including the model parameters) to the clients, on-device training on their\n",
        "local data, collecting and averaging model updates, and producing a new updated\n",
        "model at the server.\n",
        "\n",
        "Conceptually, you can think of `next` as having a functional type signature that\n",
        "looks as follows.\n",
        "\n",
        "```\n",
        "SERVER_STATE, FEDERATED_DATA -\u003e SERVER_STATE, TRAINING_METRICS\n",
        "```\n",
        "\n",
        "Let's run a single round of training and visualize the results. We can use the\n",
        "federated data we've already generated above for a sample of users."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "F3M_W9dDE6Tm"
      },
      "outputs": [],
      "source": [
        "#@test {\"timeout\": 600}\n",
        "state, loss = iterative_process.next(state, federated_train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 35
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 81,
          "status": "ok",
          "timestamp": 1550346484707,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "ggFtLPvZGtSV",
        "outputId": "98cc3964-f541-43c2-c96d-3a1455daaa50"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "26.488445"
            ]
          },
          "execution_count": 17,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#@test {\"output\": \"ignore\"}\n",
        "loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UmhReXt9G4A5"
      },
      "source": [
        "Let's run a few more rounds. As noted earlier, typically at this point you would\n",
        "pick a subset of your simulation data from a new randomly selected sample of\n",
        "users for each round in order to simulate a realistic deployment in which users\n",
        "continuously come and go, but in this interactive notebook, for the sake of\n",
        "demonstration we'll just reuse the same users, so that the system converges\n",
        "quickly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 190
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 124809,
          "status": "ok",
          "timestamp": 1550346609566,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "qrJkQuCRJP9C",
        "outputId": "3bae3641-6546-44ca-bc2c-2487502fc796"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "25.9877\n",
            "21.9768\n",
            "18.8695\n",
            "15.9183\n",
            "12.7076\n",
            "11.6411\n",
            "7.57187\n",
            "6.04966\n",
            "5.00629\n",
            "3.80206\n"
          ]
        }
      ],
      "source": [
        "#@test {\"skip\": true}\n",
        "for _ in range(10):\n",
        "  state, loss = iterative_process.next(state, federated_train_data)\n",
        "  print (loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "T4hneAcb-F2l"
      },
      "source": [
        "## Customizing the model implementation\n",
        "\n",
        "While handing your Keras model to `tff.learning.from_keras_model` or\n",
        "`tff.learning.from_compiled_keras_model` and letting TFF automatically wrap it\n",
        "for use in federated learning may be a good place to start, in many cases you\n",
        "will want to have more explicit control over the process and customize it for\n",
        "your scenario, so let's do it all over again from scratch.\n",
        "\n",
        "### Defining model variables, forward pass, and metrics\n",
        "\n",
        "The first step is to identify the TensorFlow variables we're going to work with.\n",
        "In order to make the following code more legible, let's define a data structure\n",
        "to represent the entire set. This will include variables such as `weights` and\n",
        "`bias` that we will train, as well as variables that will hold various\n",
        "cumulative statistics and counters we will update during training, such as\n",
        "`loss_sum`, `accuracy_sum`, and `num_examples`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "uqRD72WQC4u1"
      },
      "outputs": [],
      "source": [
        "MnistVariables = collections.namedtuple(\n",
        "    'MnistVariables', 'weights bias num_examples loss_sum accuracy_sum')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nkJfDcY5oXii"
      },
      "source": [
        "Here's a method that creates the variables. For the sake of simplicity, we\n",
        "represent all statistics as `tf.float32`, as that will eliminate the need for\n",
        "type conversions at a later stage. Wrapping variable initializers as lambdas is\n",
        "a requirement imposed by\n",
        "[resource variables](https://www.tensorflow.org/api_docs/python/tf/enable_resource_variables)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "H3GQHLNqCfMU"
      },
      "outputs": [],
      "source": [
        "def create_mnist_variables():\n",
        "  return MnistVariables(\n",
        "      weights = tf.Variable(\n",
        "          lambda: tf.zeros(dtype=tf.float32, shape=(784, 10)),\n",
        "          name='weights',\n",
        "          trainable=True),\n",
        "      bias = tf.Variable(\n",
        "          lambda: tf.zeros(dtype=tf.float32, shape=(10)),\n",
        "          name='bias',\n",
        "          trainable=True),\n",
        "      num_examples = tf.Variable(0.0, name='num_examples', trainable=False),\n",
        "      loss_sum = tf.Variable(0.0, name='loss_sum', trainable=False),\n",
        "      accuracy_sum = tf.Variable(0.0, name='accuracy_sum', trainable=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SrdnR0fAre-Q"
      },
      "source": [
        "With the variables for model parameters and cumulative statistics in place, we\n",
        "can now define the forward pass method that computes loss, emits predictions,\n",
        "and updates the cumulative statistics for a single batch of input data, as\n",
        "follows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "ZYSRAl-KCvC7"
      },
      "outputs": [],
      "source": [
        "def mnist_forward_pass(variables, batch):\n",
        "  y = tf.nn.softmax(tf.matmul(batch['x'], variables.weights) + variables.bias)\n",
        "  predictions = tf.cast(tf.argmax(y, 1), tf.int32)\n",
        "\n",
        "  loss = -tf.reduce_mean(tf.reduce_sum(\n",
        "      tf.one_hot(batch['y'], 10) * tf.log(y), reduction_indices=[1]))\n",
        "  accuracy = tf.reduce_mean(\n",
        "      tf.cast(tf.equal(predictions, batch['y']), tf.float32))\n",
        "\n",
        "  num_examples = tf.to_float(tf.size(batch['y']))\n",
        "\n",
        "  tf.assign_add(variables.num_examples, num_examples)\n",
        "  tf.assign_add(variables.loss_sum, loss * num_examples)\n",
        "  tf.assign_add(variables.accuracy_sum, accuracy * num_examples)\n",
        "\n",
        "  return loss, predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-gm-yx2Mr_bl"
      },
      "source": [
        "With the single-batch forward pass defined, TFF has enough information to put\n",
        "together a training loop that processes the on-device data for a single user,\n",
        "but we may want to still control the manner in which we translate the cumulative\n",
        "statistics accumulated in the course of training into a set of metrics to be\n",
        "exported by the device, so let's write another helper function to perform this\n",
        "translation.\n",
        "\n",
        "We're just going to export the average `loss` and `accuracy`, as well as the\n",
        "`num_examples`; we'll need the latter to correctly weigh the contributions from\n",
        "different users when computing the global statistics at the server."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "RkAZXhjGEekp"
      },
      "outputs": [],
      "source": [
        "def get_local_mnist_metrics(variables):\n",
        "  return collections.OrderedDict([\n",
        "      ('num_examples', variables.num_examples),\n",
        "      ('loss', variables.loss_sum / variables.num_examples),\n",
        "      ('accuracy', variables.accuracy_sum / variables.num_examples)\n",
        "    ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9ywGs1G-s1o3"
      },
      "source": [
        "Finally, we need to determine how to aggregate the local metrics emitted by each\n",
        "device. This is the only part of the code that isn't written in pure TensorFlow\n",
        "and Python - it's a *federated computation* expressed in TFF. If you'd like to\n",
        "dig deeper, skim over the [custom algorithms](custom_federated_algorithms_1.ipynb)\n",
        "tutorial, but in most applications, you won't really need to; variants of the\n",
        "pattern show below should suffice.\n",
        "\n",
        "Typically at this point, you would average metrics and sum up counters, as is\n",
        "the case in our example - we simply apply `tff.federated_sum` to metrics you\n",
        "want to sum and `tff.federated_average` to those you want to average, return the\n",
        "dictionary of what you wish to report globally, and decorate your function as\n",
        "`tff.federated_computation`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "BMr2PwkfExFI"
      },
      "outputs": [],
      "source": [
        "@tff.federated_computation\n",
        "def aggregate_local_mnist_metrics(metrics):\n",
        "  return {\n",
        "      'num_examples': tff.federated_sum(metrics.num_examples),\n",
        "      'loss': tff.federated_average(metrics.loss, metrics.num_examples),\n",
        "      'accuracy': tff.federated_average(metrics.accuracy, metrics.num_examples)\n",
        "  }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7MXGAuQRvmcp"
      },
      "source": [
        "### Constructing an instance of `tff.learning.Model`\n",
        "\n",
        "With all of the above in place, we are ready to construct a model representation\n",
        "for use with TFF similar to one that's generated for you when you let TFF ingest\n",
        "a Keras model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "blQGiTQFS9_r"
      },
      "outputs": [],
      "source": [
        "class MnistModel(tff.learning.Model):\n",
        "\n",
        "  def __init__(self):\n",
        "    self._variables = create_mnist_variables()\n",
        "\n",
        "  @property\n",
        "  def trainable_variables(self):\n",
        "    return [self._variables.weights, self._variables.bias]\n",
        "\n",
        "  @property\n",
        "  def non_trainable_variables(self):\n",
        "    return []\n",
        "\n",
        "  @property\n",
        "  def local_variables(self):\n",
        "    return [\n",
        "        self._variables.num_examples, self._variables.loss_sum,\n",
        "        self._variables.accuracy_sum\n",
        "    ]\n",
        "\n",
        "  @property\n",
        "  def input_spec(self):\n",
        "    return collections.OrderedDict([('x', tf.TensorSpec([None, 784],\n",
        "                                                        tf.float32)),\n",
        "                                    ('y', tf.TensorSpec([None], tf.int32))])\n",
        "\n",
        "  @tf.contrib.eager.function()\n",
        "  def forward_pass(self, batch, training=True):\n",
        "    del training\n",
        "    loss, predictions = mnist_forward_pass(self._variables, batch)\n",
        "    return tff.learning.BatchOutput(loss=loss, predictions=predictions)\n",
        "\n",
        "  @tf.contrib.eager.function()\n",
        "  def report_local_outputs(self):\n",
        "    return get_local_mnist_metrics(self._variables)\n",
        "\n",
        "  @property\n",
        "  def federated_output_computation(self):\n",
        "    return aggregate_local_mnist_metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sMN1AszMwLHL"
      },
      "source": [
        "As you can see, the abstract methods and properties defined by\n",
        "`tff.learning.Model` correspond closely to the code snippets that introduce the\n",
        "variables, define the loss and statistics that we introduced in the preceding\n",
        "section.\n",
        "\n",
        "Here are a few points worth highlighting:\n",
        "\n",
        "*   All state that your model will use must be captured as TensorFlow variables,\n",
        "    as TFF does not use Python at runtime (remember your code should be written\n",
        "    such that it can be deployed to mobile devices; see the\n",
        "    [custom algorithms](custom_federated_algorithms.ipynb) tutorial for a more\n",
        "    in-depth commentary on the reasons). The variables should always be created\n",
        "    in the constructor.\n",
        "*   Your model should describe what form of data it accepts (`input_spec`), as\n",
        "    in general, TFF is a stronly-typed environment and wants to determine type\n",
        "    signatures for all components. Declaring the format of your model's input is\n",
        "    an essential part of it.\n",
        "*   Although technically not required, we recommend wrapping all TensorFlow\n",
        "    logic (forward pass, metric calculations) as `tf.contrib.eager.function`s."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9DVhXk2Bu-GU"
      },
      "source": [
        "While the above is technically sufficient, and TFF can take over from here,\n",
        "there's one more optional part you may want to customize, and that's defining\n",
        "the optimizer and how it's applied to the data to perform a single step of\n",
        "training.\n",
        "\n",
        "While TFF can do it for you, it's common to take control over this step as well,\n",
        "e.g., as follows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "q1w7US3PFN2p"
      },
      "outputs": [],
      "source": [
        "class MnistTrainableModel(MnistModel, tff.learning.TrainableModel):\n",
        "\n",
        "  @tf.contrib.eager.defun()\n",
        "  def train_on_batch(self, batch):\n",
        "    output = self.forward_pass(batch)\n",
        "    optimizer = tf.train.GradientDescentOptimizer(0.1)\n",
        "    optimizer.minimize(output.loss, var_list=self.trainable_variables)\n",
        "    return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hVBugKP3yw03"
      },
      "source": [
        "### Simulating federated training with the new model\n",
        "\n",
        "With all the above in place, the remainder of the process looks like what we've\n",
        "seen already - just replace the model constructor with the constructor of our\n",
        "new model class, and use the two federated computations in the iterative process\n",
        "you created to cycle through training rounds."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "FK3c8_leS9_t"
      },
      "outputs": [],
      "source": [
        "iterative_process = tff.learning.build_federated_averaging_process(\n",
        "    MnistTrainableModel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Jv_LiggwS9_u"
      },
      "outputs": [],
      "source": [
        "state = iterative_process.initialize()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "W0TKgDqHKQaP"
      },
      "outputs": [],
      "source": [
        "#@test {\"timeout\": 600}\n",
        "state, metrics = iterative_process.next(state, federated_train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 35
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 79,
          "status": "ok",
          "timestamp": 1550346637464,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "hmlLydWYKZPc",
        "outputId": "7b498af1-9481-4254-e929-5406c5cbcb39"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\u003caccuracy=0.117091,loss=26.5301,num_examples=2750.0\u003e'"
            ]
          },
          "execution_count": 29,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#@test {\"output\": \"ignore\"}\n",
        "str(metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 190
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 237663,
          "status": "ok",
          "timestamp": 1550346875214,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "gFkv0yJEGhue",
        "outputId": "97c281d4-fcd9-4b36-f620-338f751a4cc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u003caccuracy=0.134909,loss=25.4888,num_examples=2750.0\u003e\n",
            "\u003caccuracy=0.140364,loss=nan,num_examples=2750.0\u003e\n",
            "\u003caccuracy=0.214545,loss=19.5845,num_examples=2750.0\u003e\n",
            "\u003caccuracy=0.269455,loss=16.1853,num_examples=2750.0\u003e\n",
            "\u003caccuracy=0.294545,loss=13.7774,num_examples=2750.0\u003e\n",
            "\u003caccuracy=0.343636,loss=12.177,num_examples=2750.0\u003e\n",
            "\u003caccuracy=0.392727,loss=9.11823,num_examples=2750.0\u003e\n",
            "\u003caccuracy=0.472,loss=7.58817,num_examples=2750.0\u003e\n",
            "\u003caccuracy=0.461455,loss=7.01797,num_examples=2750.0\u003e\n",
            "\u003caccuracy=0.606182,loss=4.20436,num_examples=2750.0\u003e\n"
          ]
        }
      ],
      "source": [
        "#@test {\"skip\": true}\n",
        "for _ in range(10):\n",
        "  state, metrics = iterative_process.next(state, federated_train_data)\n",
        "  print (metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "m7lz59lMJ0kj"
      },
      "source": [
        "## Evaluation\n",
        "\n",
        "All of our experiments so far focused on the same set of training data, which of\n",
        "course brings potential concerns about overfitting. Now, in a real systems,\n",
        "those concerns would be mitigated by the presence of millions of users, only a\n",
        "tiny fraction of whom participate in each round of training, but in a\n",
        "simulation, we need to be more careful, especially that we are reusing the same\n",
        "users for demonstration purposes.\n",
        "\n",
        "To perform evaluation, you can construct another *federated computation*\n",
        "designed for just this purpose, as follows, using the\n",
        "`tff.learning.build_federated_evaluation` function, and passing in your model\n",
        "constructor as an argument. Note that unlike in our earlier example, where we've\n",
        "used `MnistTrainableModel`, it suffices to pass the `MnistModel`. Evaluation\n",
        "doesn't perform gradient descent, and there's no need to construct optimizers.\n",
        "Your model class just needs to support the `tff.learning.Model.forward_pass`\n",
        "method, and the associated ones for reporting and aggregating per-client\n",
        "metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "nRiXyqnXM2VO"
      },
      "outputs": [],
      "source": [
        "evaluation = tff.learning.build_federated_evaluation(MnistModel)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uwfINGoNQEuV"
      },
      "source": [
        "You can inspect the abstract type signature of the evaluation function as follows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 55
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 78,
          "status": "ok",
          "timestamp": 1550346875974,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "3q5ueoO0NDNb",
        "outputId": "bb57521b-7769-4a5b-f428-b46a961f337f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'(\u003c\u003ctrainable=\u003cweights=float32[784,10],bias=float32[10]\u003e,non_trainable=\u003c\u003e\u003e@SERVER,{\u003cx=float32[?,784],y=int32[?]\u003e*}@CLIENTS\u003e -\u003e \u003caccuracy=float32@SERVER,loss=float32@SERVER,num_examples=float32@SERVER\u003e)'"
            ]
          },
          "execution_count": 32,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str(evaluation.type_signature)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XA3v7f2SQs6q"
      },
      "source": [
        "No need to be concerned about the details at this point, just be aware that it\n",
        "takes the following general form, similar to `tff.utils.IterativeProcess.next`\n",
        "but with two important differences. First, we are not returning server state,\n",
        "since evaluation doesn't modify the model or any other aspect of state - you can\n",
        "think of it as stateless. Second, evaluation only needs the model, and doesn't\n",
        "require any other part of server state that might be associated with training,\n",
        "such as optimizer variables.\n",
        "\n",
        "```\n",
        "SERVER_MODEL, FEDERATED_DATA -\u003e TRAINING_METRICS\n",
        "```\n",
        "\n",
        "Let's invoke evaluation on the latest state we arrived at during training. In\n",
        "order to extract the latest trained model from the server state, you simply\n",
        "access the `.model` member, as follows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "OX4Sk_uyOaYa"
      },
      "outputs": [],
      "source": [
        "#@test {\"output\": \"ignore\"}\n",
        "train_metrics = evaluation(state.model, federated_train_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UeEsdwJgRGMW"
      },
      "source": [
        "Here's what we get. Note the numbers look marginally bettre than what was\n",
        "reported by the last round of training above. By convention, the training\n",
        "metrics reported by the iterative training process generally reflect the\n",
        "performance of the model at the beginning of the training round, so the\n",
        "evaluation metrics will always be one step ahead."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 35
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 77,
          "status": "ok",
          "timestamp": 1550346879640,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "zwCy1IPxOfiT",
        "outputId": "bf3fe0eb-0ed9-4f16-fe64-d9c4552e2d85"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\u003caccuracy=0.64,loss=3.42009,num_examples=2750.0\u003e'"
            ]
          },
          "execution_count": 34,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#@test {\"output\": \"ignore\"}\n",
        "str(train_metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SpfgdNDoRjPy"
      },
      "source": [
        "Now, let's compile a test sample of federated data and rerun evaluation on the\n",
        "test data. The data will come from the same sample of real users, but from a\n",
        "distinct held-out data set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 52
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 153,
          "status": "ok",
          "timestamp": 1550346879860,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "in8vProVNc04",
        "outputId": "167782bc-cef9-4ff5-e148-3608bc58af24"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3,\n",
              " \u003cDatasetV1Adapter shapes: OrderedDict([(x, (None, 784)), (y, (None,))]), types: OrderedDict([(x, tf.float32), (y, tf.int32)])\u003e)"
            ]
          },
          "execution_count": 35,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "federated_test_data = make_federated_data(emnist_test, sample_clients)\n",
        "\n",
        "len(federated_test_data), federated_test_data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "ty-ZwfE0NJfV"
      },
      "outputs": [],
      "source": [
        "#@test {\"output\": \"ignore\"}\n",
        "test_metrics = evaluation(state.model, federated_test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "height": 35
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 78,
          "status": "ok",
          "timestamp": 1550346882138,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 480
        },
        "id": "e5fGtIJYNqYH",
        "outputId": "8ad870a4-4ab2-429b-87d4-150e83b823c7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\u003caccuracy=0.757576,loss=2.72042,num_examples=330.0\u003e'"
            ]
          },
          "execution_count": 37,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#@test {\"output\": \"ignore\"}\n",
        "str(test_metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "67vYxrDWzRcj"
      },
      "source": [
        "This concludes the tutorial. As noted above, we encourage you to play with the\n",
        "parameters (e.g., batch sizes, number of users, epochs, learning ratres, etc.),\n",
        "and to modify the code above to simulate training on random samples of users in\n",
        "each round, and to explore other tutorials we've developed."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "last_runtime": {
        "build_target": "",
        "kind": "local"
      },
      "name": "Federated Learning for Image Classification",
      "provenance": [
        {
          "file_id": "1ReQJfPpiNTRrFhK-zK6InyBId1n_DGLm",
          "timestamp": 1547751366697
        }
      ],
      "version": "0.3.2"
    },
    "kernelspec": {
      "display_name": "Python 2",
      "name": "python2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
